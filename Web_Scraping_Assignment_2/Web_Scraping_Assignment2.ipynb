{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c827ef5",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9991bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets now import all the required libraries\n",
    "import selenium    \n",
    "import pandas as pd    \n",
    "from selenium import webdriver   \n",
    "import warnings   \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5489dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Web Driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba397b",
   "metadata": {},
   "source": [
    "# Answer-1 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e5376dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "\n",
    "#First get the webpage https://www.naukri.com/\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a686c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation.send_keys('Data Analyst')\n",
    "\n",
    "search_field_location = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\") \n",
    "search_field_location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7e8e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click the search button.\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67d2a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then scrape the data for the first 10 jobs results you get.\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36b561c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Jr . Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Reference Data Analyst',\n",
       " 'Hiring For Data Analyst with SAP ABAP & BW - C2H Wipro',\n",
       " 'Officer - Category Demand Management ( Data Analyst)',\n",
       " 'Software Technologist II - Data Analyst',\n",
       " 'SAS Analyst / data Analyst / Business analyst - Sas + SQL']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 job titles\n",
    "titles_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in titles_tags:         \n",
    "    title=i.text              \n",
    "    job_title.append(title)  \n",
    "job_title[0:10]              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d64b046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Jayanagar)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 location \n",
    "location_tags = driver.find_elements_by_xpath(\"//li[@ class='fleft grey-text br2 placeHolderLi location']/span[1]\") \n",
    "location_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in location_tags:          \n",
    "    location=i.text             \n",
    "    job_location.append(location)  \n",
    "job_location[0:10]               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3891363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CAREERDOST ENTERPRISE',\n",
       " 'Capco',\n",
       " 'Gsn Games India',\n",
       " 'Armorblox',\n",
       " 'G S E-COMMERCE PVT LTD',\n",
       " 'Deutsche Bank',\n",
       " 'MILLION MINDS INFOTECH PRIVATE LIMITED',\n",
       " 'Myntra',\n",
       " 'Philips',\n",
       " 'Leading US MNC into analytics']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 company names\n",
    "companies_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\") \n",
    "companies_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in companies_tags:          \n",
    "    company=i.text             \n",
    "    company_name.append(company)  \n",
    "company_name[0:10]               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c6c4c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-5 Yrs',\n",
       " '7-12 Yrs',\n",
       " '3-7 Yrs',\n",
       " '0-2 Yrs',\n",
       " '4-7 Yrs',\n",
       " '2-5 Yrs',\n",
       " '7-10 Yrs',\n",
       " '1-4 Yrs',\n",
       " '5-8 Yrs',\n",
       " '2-7 Yrs']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 experience required data\n",
    "experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\") \n",
    "experience_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in experience_tags:          \n",
    "    experience=i.text             \n",
    "    experience_required.append(experience)  \n",
    "experience_required[0:10]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a4e9e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business and Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CAREERDOST ENTERPRISE</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Capco</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gsn Games India</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jr . Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Armorblox</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Jayanagar)</td>\n",
       "      <td>G S E-COMMERCE PVT LTD</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reference Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Analyst with SAP ABAP &amp; BW - C...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MILLION MINDS INFOTECH PRIVATE LIMITED</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Officer - Category Demand Management ( Data An...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Software Technologist II - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SAS Analyst / data Analyst / Business analyst ...</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Leading US MNC into analytics</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                          Business and Data Analyst   \n",
       "1                                Senior Data Analyst   \n",
       "2                                Senior Data Analyst   \n",
       "3                                  Jr . Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5                             Reference Data Analyst   \n",
       "6  Hiring For Data Analyst with SAP ABAP & BW - C...   \n",
       "7  Officer - Category Demand Management ( Data An...   \n",
       "8            Software Technologist II - Data Analyst   \n",
       "9  SAS Analyst / data Analyst / Business analyst ...   \n",
       "\n",
       "                                            location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                     Bangalore/Bengaluru(Jayanagar)   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "\n",
       "                                  company experience_required  \n",
       "0                   CAREERDOST ENTERPRISE             0-5 Yrs  \n",
       "1                                   Capco            7-12 Yrs  \n",
       "2                         Gsn Games India             3-7 Yrs  \n",
       "3                               Armorblox             0-2 Yrs  \n",
       "4                  G S E-COMMERCE PVT LTD             4-7 Yrs  \n",
       "5                           Deutsche Bank             2-5 Yrs  \n",
       "6  MILLION MINDS INFOTECH PRIVATE LIMITED            7-10 Yrs  \n",
       "7                                  Myntra             1-4 Yrs  \n",
       "8                                 Philips             5-8 Yrs  \n",
       "9           Leading US MNC into analytics             2-7 Yrs  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "jobs = pd.DataFrame({})\n",
    "jobs['title'] = job_title\n",
    "jobs['location'] = job_location\n",
    "jobs['company'] = company_name\n",
    "jobs['experience_required'] = experience_required\n",
    "jobs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f323e1a1",
   "metadata": {},
   "source": [
    "# Answer-2 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3474bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "\n",
    "#First get the webpage https://www.naukri.com/\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d15483ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation.send_keys('Data Scientist')\n",
    "\n",
    "search_field_location = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\") \n",
    "search_field_location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67566084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click the search button.\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c187a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then scrape the data for the first 10 jobs results you get.\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a015e67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist',\n",
       " 'Cognitive/AI Senior Data Scientist',\n",
       " 'Lead - Data Scientist',\n",
       " 'Senior Associate - Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Staff Data Scientist',\n",
       " 'Job Opening with Wipro For Data Scientist - SAS',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist -Python+ML(5-7 years)',\n",
       " 'Senior Data Scientist']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 job titles\n",
    "titles_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in titles_tags:         \n",
    "    title=i.text              \n",
    "    job_title.append(title)  \n",
    "job_title[0:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "15b77fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Remote',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 location \n",
    "location_tags = driver.find_elements_by_xpath(\"//li[@ class='fleft grey-text br2 placeHolderLi location']/span[1]\") \n",
    "location_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in location_tags:          \n",
    "    location=i.text             \n",
    "    job_location.append(location)  \n",
    "job_location[0:10]             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cb3cce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Walmart',\n",
       " 'IBM',\n",
       " 'Applied Materials',\n",
       " 'Affine',\n",
       " 'Applied Materials',\n",
       " 'Walmart',\n",
       " 'Wipro',\n",
       " 'CRED',\n",
       " 'Knowledge Foundry Business Solutions Pvt. Ltd.',\n",
       " 'Course5']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 company names\n",
    "companies_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\") \n",
    "companies_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in companies_tags:          \n",
    "    company=i.text             \n",
    "    company_name.append(company)  \n",
    "company_name[0:10]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b5adb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cognitive/AI Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Associate - Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Affine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Job Opening with Wipro For Data Scientist - SAS</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CRED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist -Python+ML(5-7 years)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Knowledge Foundry Business Solutions Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Course5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "0                            Senior Data Scientist   \n",
       "1               Cognitive/AI Senior Data Scientist   \n",
       "2                            Lead - Data Scientist   \n",
       "3                Senior Associate - Data Scientist   \n",
       "4                                   Data Scientist   \n",
       "5                             Staff Data Scientist   \n",
       "6  Job Opening with Wipro For Data Scientist - SAS   \n",
       "7                                   Data Scientist   \n",
       "8      Senior Data Scientist -Python+ML(5-7 years)   \n",
       "9                            Senior Data Scientist   \n",
       "\n",
       "                                            location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                             Remote   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9            Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "\n",
       "                                          company  \n",
       "0                                         Walmart  \n",
       "1                                             IBM  \n",
       "2                               Applied Materials  \n",
       "3                                          Affine  \n",
       "4                               Applied Materials  \n",
       "5                                         Walmart  \n",
       "6                                           Wipro  \n",
       "7                                            CRED  \n",
       "8  Knowledge Foundry Business Solutions Pvt. Ltd.  \n",
       "9                                         Course5  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "jobs = pd.DataFrame({})\n",
    "jobs['title'] = job_title\n",
    "jobs['location'] = job_location\n",
    "jobs['company'] = company_name\n",
    "jobs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674a9d8",
   "metadata": {},
   "source": [
    "# Answer-3 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d6fe6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "# You have to use the location and salary filter.\n",
    "# You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "# You have to scrape the job-title, job-location, company name, experience required.\n",
    "# The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "\n",
    "\n",
    "#First get the webpage https://www.naukri.com/\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb82d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter “Data Scientist” in “Skill, Designations, Companies” field.\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c406aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click the search button.\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c3c62898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then apply the location filter and salary filter by checking the respective boxes\n",
    "location_filter_checkbox = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[3]/label/i\")\n",
    "location_filter_checkbox.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6fed2d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter_checkbox = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[2]/label/i\")\n",
    "salary_filter_checkbox.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c886ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then scrape the data for the first 10 jobs results you get.\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fb5886ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Associate Data Scientist',\n",
       " 'Associate Scientist - Data Engineering',\n",
       " 'Data Scientist/ Machine Learning, 2022 Passout Can also apply',\n",
       " 'Hiring For Senior Data Scientist-Noida',\n",
       " 'Hiring For Data Analyst and Data Scientist For Gurgaon Location',\n",
       " 'Opening For Data Scientist',\n",
       " 'Data Scientist (freelance)',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 job titles\n",
    "titles_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in titles_tags:         \n",
    "    title=i.text              \n",
    "    job_title.append(title)  \n",
    "job_title[0:10]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "575987a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida, Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Hyderabad/Secunderabad, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Noida, Greater Noida, Delhi / NCR',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'New Delhi, Delhi',\n",
       " 'Gurgaon, Bengaluru',\n",
       " 'New Delhi']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 location \n",
    "location_tags = driver.find_elements_by_xpath(\"//li[@ class='fleft grey-text br2 placeHolderLi location']/span[1]\") \n",
    "location_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in location_tags:          \n",
    "    location=i.text             \n",
    "    job_location.append(location)  \n",
    "job_location[0:10]               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f3bf42b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ashkom Media India Private Limited',\n",
       " 'Optum',\n",
       " 'AXA Technology Services India Pvt. Ltd',\n",
       " 'Creative Hands HR Consultancy',\n",
       " 'Lumiq.ai',\n",
       " 'Shadow Placements',\n",
       " 'Care Health Insurance',\n",
       " '2Coms',\n",
       " 'BlackBuck',\n",
       " 'Boston Consulting Group']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 company names\n",
    "companies_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\") \n",
    "companies_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in companies_tags:          \n",
    "    company=i.text             \n",
    "    company_name.append(company)  \n",
    "company_name[0:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4ba5209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-6 Yrs',\n",
       " '1-5 Yrs',\n",
       " '2-5 Yrs',\n",
       " '0-4 Yrs',\n",
       " '2-6 Yrs',\n",
       " '3-7 Yrs',\n",
       " '1-5 Yrs',\n",
       " '2-7 Yrs',\n",
       " '3-7 Yrs',\n",
       " '2-5 Yrs']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets extract all the tags having the first 10 experience required data\n",
    "experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\") \n",
    "experience_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in experience_tags:          \n",
    "    experience=i.text             \n",
    "    experience_required.append(experience)  \n",
    "experience_required[0:10]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6d54288f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Scientist - Data Engineering</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AXA Technology Services India Pvt. Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist/ Machine Learning, 2022 Passout...</td>\n",
       "      <td>Hyderabad/Secunderabad, Ahmedabad, Chennai, Ba...</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For Senior Data Scientist-Noida</td>\n",
       "      <td>Noida, Greater Noida, Delhi / NCR</td>\n",
       "      <td>Lumiq.ai</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst and Data Scientist For...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Shadow Placements</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Opening For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Care Health Insurance</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                     Data Scientist   \n",
       "1                           Associate Data Scientist   \n",
       "2             Associate Scientist - Data Engineering   \n",
       "3  Data Scientist/ Machine Learning, 2022 Passout...   \n",
       "4             Hiring For Senior Data Scientist-Noida   \n",
       "5  Hiring For Data Analyst and Data Scientist For...   \n",
       "6                         Opening For Data Scientist   \n",
       "7                         Data Scientist (freelance)   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            location  \\\n",
       "0                         Noida, Bangalore/Bengaluru   \n",
       "1                                   Gurgaon/Gurugram   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3  Hyderabad/Secunderabad, Ahmedabad, Chennai, Ba...   \n",
       "4                  Noida, Greater Noida, Delhi / NCR   \n",
       "5               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                   New Delhi, Delhi   \n",
       "8                                 Gurgaon, Bengaluru   \n",
       "9                                          New Delhi   \n",
       "\n",
       "                                  company experience_required  \n",
       "0      Ashkom Media India Private Limited             3-6 Yrs  \n",
       "1                                   Optum             1-5 Yrs  \n",
       "2  AXA Technology Services India Pvt. Ltd             2-5 Yrs  \n",
       "3           Creative Hands HR Consultancy             0-4 Yrs  \n",
       "4                                Lumiq.ai             2-6 Yrs  \n",
       "5                       Shadow Placements             3-7 Yrs  \n",
       "6                   Care Health Insurance             1-5 Yrs  \n",
       "7                                   2Coms             2-7 Yrs  \n",
       "8                               BlackBuck             3-7 Yrs  \n",
       "9                 Boston Consulting Group             2-5 Yrs  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "jobs = pd.DataFrame({})\n",
    "jobs['title'] = job_title\n",
    "jobs['location'] = job_location\n",
    "jobs['company'] = company_name\n",
    "jobs['experience_required'] = experience_required\n",
    "jobs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf00e5",
   "metadata": {},
   "source": [
    "# Answer-4 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc457984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "#1. Brand 2. Product Description 3. Price\n",
    "\n",
    "#Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "745ab950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter “sunglasses” in the search field where “search for products, brands andmore” is written and click the search icon.\n",
    "search_field_products = driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_field_products.send_keys('sunglasses')\n",
    "\n",
    "#clicking on search button\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baa68728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store product brands, description and price.\n",
    "product_brands = []\n",
    "product_description = []\n",
    "product_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3f6687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the required data as usual.\n",
    "#so lets extract all the tags having the product brands, description and price data from the first page, go to the “Next” Button at the bottom of the page , then click on it.\n",
    "\n",
    "for i in range(0,3):                  #running for loop with range to run this loop 3 times \n",
    "    brand_tags = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    description_tags = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    price_tags = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    \n",
    "    for i in brand_tags:              #iterating over web element of title\n",
    "        brand = i.text                #extracting text from each web element\n",
    "        product_brands.append(brand)  #appending each exracted text into empty list\n",
    "    for j in description_tags:\n",
    "        description = j.text\n",
    "        product_description.append(description)\n",
    "    for k in price_tags:\n",
    "        price = k.text\n",
    "        product_price.append(price)\n",
    "    \n",
    "    next_button = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(next_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_button[0].get_attribute('href'))\n",
    "\n",
    "    #next_button.click()      #locating web element of next button and then clicking on next button\n",
    "    #time.sleep(5)            #using time to pause the search engine for 5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8823e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(product_brands),len(product_description),len(product_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b93b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "products = pd.DataFrame({})\n",
    "products['brand'] = product_brands\n",
    "products['description'] = product_description\n",
    "products['price'] = product_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46415bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAJERO</td>\n",
       "      <td>UV Protection, Polarized, Riding Glasses Retro...</td>\n",
       "      <td>₹1,273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Riding Glasses, UV Protection Clubmaster, Wayf...</td>\n",
       "      <td>₹329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (54)</td>\n",
       "      <td>₹649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "      <td>₹198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>CRYSTAL CART</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (50)</td>\n",
       "      <td>₹649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            brand                                        description   price\n",
       "0          BAJERO  UV Protection, Polarized, Riding Glasses Retro...  ₹1,273\n",
       "1    Singco India  Riding Glasses, UV Protection Clubmaster, Wayf...    ₹329\n",
       "2        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹719\n",
       "3          SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...    ₹283\n",
       "4        Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹639\n",
       "..            ...                                                ...     ...\n",
       "95  VINCENT CHASE              UV Protection Cat-eye Sunglasses (54)    ₹649\n",
       "96     LIZA ANGEL  Riding Glasses, Night Vision Spectacle Sunglas...    ₹198\n",
       "97         PIRASO              UV Protection Aviator Sunglasses (55)    ₹236\n",
       "98   CRYSTAL CART  UV Protection, Gradient Round Sunglasses (Free...    ₹419\n",
       "99  VINCENT CHASE          UV Protection Rectangular Sunglasses (50)    ₹649\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f480422",
   "metadata": {},
   "source": [
    "# Answer-5 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d8922ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-%20earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC%20TSVZAXUHGREPBFGI&marketplace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6aaa91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then click the all review link button.\n",
    "all_review_link_button = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a\")\n",
    "all_review_link_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d9991f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store product ratings, review summary and full review.\n",
    "product_rating = []\n",
    "product_review_summary = []\n",
    "product_full_review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c4bad07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you have to scrape the attributes.These are: \n",
    "#1. Rating 2. Review summary 3. Full review 4. You have to scrape this data for first 100 reviews.\n",
    "\n",
    "for i in range(0,11):\n",
    "    rating_tags = driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]\")\n",
    "    review_summary_tags = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    full_review_tags = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    \n",
    "    for i in rating_tags:\n",
    "        rating = i.text\n",
    "        rating = rating[0:1]\n",
    "        product_rating.append(rating)\n",
    "        \n",
    "    for j in review_summary_tags:\n",
    "        review_summary = j.text\n",
    "        product_review_summary.append(review_summary)\n",
    "    \n",
    "    for k in full_review_tags:\n",
    "        full_review = k.text\n",
    "        product_full_review.append(full_review)\n",
    "    \n",
    "    next_button = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(next_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bd933c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 110 110\n"
     ]
    }
   ],
   "source": [
    "print(len(product_rating),len(product_review_summary),len(product_full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "497d8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "products = pd.DataFrame({})\n",
    "products['rating'] = product_rating\n",
    "products['review_summary'] = product_review_summary\n",
    "products['full_review'] = product_full_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a77236ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A perfect phone and a good battery super camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Undoubtedly Iphone 11 is the most successful m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>I purchased the iPhone 11 a month back. I must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       review_summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5            Excellent   \n",
       "96      5               Super!   \n",
       "97      5    Worth every penny   \n",
       "98      5            Fabulous!   \n",
       "99      5            Wonderful   \n",
       "\n",
       "                                          full_review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  A perfect phone and a good battery super camer...  \n",
       "96  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "97  Undoubtedly Iphone 11 is the most successful m...  \n",
       "98  I purchased the iPhone 11 a month back. I must...  \n",
       "99  Nice value for money good and best price I pho...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc012439",
   "metadata": {},
   "source": [
    "# Answer-6 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "782d4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape data for first 100 sneakers you find when you visit flipkart.com \n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "20411c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for “sneakers” in the search field.\n",
    "search_field_products = driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_field_products.send_keys('sneakers')\n",
    "\n",
    "#clicking on search button\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "453cef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store product brands, description and price.\n",
    "product_brands = []\n",
    "product_description = []\n",
    "product_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1a318058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You have to scrape 4 attributes of each sneaker: 1. Brand 2. Product Description 3. Price\n",
    "for i in range(0,3):                  #running for loop with range to run this loop 3 times \n",
    "    brand_tags = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    description_tags = driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")\n",
    "    price_tags = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    \n",
    "    for i in brand_tags:              #iterating over web element of title\n",
    "        brand = i.text                #extracting text from each web element\n",
    "        product_brands.append(brand)  #appending each exracted text into empty list\n",
    "    \n",
    "    for j in description_tags:\n",
    "        description = j.text\n",
    "        product_description.append(description)\n",
    "    \n",
    "    for k in price_tags:\n",
    "        price = k.text\n",
    "        product_price.append(price)\n",
    "    \n",
    "    next_button = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(next_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "477613ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(product_brands),len(product_description),len(product_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c2a70885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "products = pd.DataFrame({})\n",
    "products['brand'] = product_brands\n",
    "products['description'] = product_description\n",
    "products['price'] = product_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5bacbccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOC</td>\n",
       "      <td>611 casual sneaker shoes for men Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corsac</td>\n",
       "      <td>STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jimnastic shoes</td>\n",
       "      <td>Casual for men Sneakers For Men</td>\n",
       "      <td>₹397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>City Soles</td>\n",
       "      <td>Canvas Sneakers for Men Sneakers For Men</td>\n",
       "      <td>₹745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LE GREEM</td>\n",
       "      <td>Comfortable &amp; Ultra Light Weight Sneaker Sneak...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>AKIMBO</td>\n",
       "      <td>PLAN WHITE SHOE Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              brand                                        description price\n",
       "0            BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men  ₹488\n",
       "1               HOC  611 casual sneaker shoes for men Sneakers For Men  ₹499\n",
       "2          URBANBOX                          Sneakers Sneakers For Men  ₹198\n",
       "3            BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men  ₹295\n",
       "4            corsac  STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...  ₹499\n",
       "..              ...                                                ...   ...\n",
       "95  Jimnastic shoes                    Casual for men Sneakers For Men  ₹397\n",
       "96       City Soles           Canvas Sneakers for Men Sneakers For Men  ₹745\n",
       "97         LE GREEM  Comfortable & Ultra Light Weight Sneaker Sneak...  ₹499\n",
       "98           AKIMBO                   PLAN WHITE SHOE Sneakers For Men  ₹499\n",
       "99         RapidBox                                   Sneakers For Men  ₹720\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d38505",
   "metadata": {},
   "source": [
    "# Answer-7 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f1ae56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go to the link - https://www.myntra.com/shoes\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b2f21cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”\n",
    "price_filter_checkbox = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_filter_checkbox.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df283900",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_filter_checkbox = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "color_filter_checkbox.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e00f165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_brands = []\n",
    "product_description = []\n",
    "product_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ff9b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract all the tags having the first 100 product brands, description, price.\n",
    "for i in range(0,2):   \n",
    "    brand_tags = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    description_tags = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "    price_tags = driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\")\n",
    "    \n",
    "    for i in brand_tags:     \n",
    "        brand=i.text   \n",
    "        product_brands.append(brand)\n",
    "        \n",
    "    for j in description_tags:\n",
    "        description=j.text  \n",
    "        product_description.append(description)\n",
    "        \n",
    "    for k in price_tags:\n",
    "        price=k.text  \n",
    "        product_price.append(price)\n",
    "        \n",
    "    next_button = driver.find_elements_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "    try:\n",
    "        driver.get(next_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aaf42a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(product_brands),len(product_description),len(product_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "758f8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "products = pd.DataFrame({})\n",
    "products['brands'] = product_brands\n",
    "products['description'] = product_description\n",
    "products['price'] = product_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9c69aaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brands</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td></td>\n",
       "      <td>Rs. 13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Textured Slip-On Sneakers</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>Rs. 7649Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Vantage 2 Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Textured Leather Formal Loafers</td>\n",
       "      <td>Rs. 13990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>Women Trekking Shoes</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Black Formal Derby Shoes</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  brands                          description  \\\n",
       "0                   ALDO            Men Leather Driving Shoes   \n",
       "1                   ALDO                                        \n",
       "2                   ALDO        Men Textured Slip-On Sneakers   \n",
       "3               Skechers           Men Max Cushioning Running   \n",
       "4           UNDER ARMOUR          Men Vantage 2 Running Shoes   \n",
       "..                   ...                                  ...   \n",
       "95  Heel & Buckle London  Men Textured Leather Formal Loafers   \n",
       "96               Bugatti                    Men Walking Shoes   \n",
       "97               Bugatti      Men Solid Leather Formal Derbys   \n",
       "98              Columbia                 Women Trekking Shoes   \n",
       "99               Bugatti         Men Black Formal Derby Shoes   \n",
       "\n",
       "               price  \n",
       "0          Rs. 12999  \n",
       "1          Rs. 13999  \n",
       "2          Rs. 12999  \n",
       "3   Rs. 7649Rs. 8999  \n",
       "4           Rs. 7999  \n",
       "..               ...  \n",
       "95         Rs. 13990  \n",
       "96          Rs. 8999  \n",
       "97          Rs. 9499  \n",
       "98          Rs. 8999  \n",
       "99         Rs. 11999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef97bee",
   "metadata": {},
   "source": [
    "# Answer-8 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "37e66478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go to webpage https://www.amazon.in/\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f6c92b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter “Laptop” in the search field and then click the search icon.\n",
    "search_field = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search_field.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5cdca98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_xpath(\"//html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "93ccb809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "cpu_type_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[4]/li[13]/span/a/span\")\n",
    "cpu_type_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "105df393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract all the tags having the laptop titles\n",
    "product_titles = []\n",
    "product_ratings = []\n",
    "product_price = []\n",
    "\n",
    "title_tags = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "rating_tags = driver.find_elements_by_xpath(\"//div[@class='a-row a-size-small']/span/span/a/i/span\")\n",
    "price_tags = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "    \n",
    "for i in title_tags:     \n",
    "    title=i.text   \n",
    "    product_titles.append(title)\n",
    "    product_titles = product_titles[0:10]\n",
    "        \n",
    "for j in rating_tags:     \n",
    "    rating=j.text   \n",
    "    product_ratings.append(rating)\n",
    "    product_ratings = product_ratings[0:10]\n",
    "    \n",
    "for k in price_tags:     \n",
    "    price=k.text   \n",
    "    product_price.append(price)\n",
    "    product_price = product_price[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "be829a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(product_titles),len(product_ratings),len(product_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a5014865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "products = pd.DataFrame({})\n",
    "products['title'] = product_titles\n",
    "products['rating'] = product_ratings\n",
    "products['price'] = product_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6636ef40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Gram 14 inches Ultra-Light Intel Evo 11th G...</td>\n",
       "      <td></td>\n",
       "      <td>88,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Gram Intel Evo 11th Gen Core i7 17 inches U...</td>\n",
       "      <td></td>\n",
       "      <td>93,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 Ev...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...</td>\n",
       "      <td></td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td></td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td></td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell E6410 Latitude 14 Inch Screen L...</td>\n",
       "      <td></td>\n",
       "      <td>19,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td></td>\n",
       "      <td>85,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell Latitude Laptop E7480 Intel Cor...</td>\n",
       "      <td></td>\n",
       "      <td>64,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title rating   price\n",
       "0  LG Gram 14 inches Ultra-Light Intel Evo 11th G...         88,499\n",
       "1  LG Gram Intel Evo 11th Gen Core i7 17 inches U...         93,999\n",
       "2  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...         57,490\n",
       "3  Samsung Galaxy Book2 Intel 12th Gen core i7 Ev...         79,990\n",
       "4  HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...         86,990\n",
       "5  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...         89,990\n",
       "6  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....         86,990\n",
       "7  (Renewed) Dell E6410 Latitude 14 Inch Screen L...         19,990\n",
       "8  HP Pavilion x360 11th Gen Intel Core i7 14 inc...         85,890\n",
       "9  (Renewed) Dell Latitude Laptop E7480 Intel Cor...         64,990"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d656c7",
   "metadata": {},
   "source": [
    "# Answer-9 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a176598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "#First get the webpage https://www.ambitionbox.com/\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36e0d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on the Job option.\n",
    "job_option_link = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]')\n",
    "job_option_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba29e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "search_field_designation = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "search_field_designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af2c5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn_click = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button\")\n",
    "search_btn_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca9fabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "location_option = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]')\n",
    "location_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "495a5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_location = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "search_location.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c712e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_click = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/input\")\n",
    "location_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acbb832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store job company names, no.of days ago post and ratings.\n",
    "company_names = []\n",
    "days_ago = []\n",
    "company_rating = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36fe0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then scrape the data for the first 10 jobs results you get.\n",
    "company_name_tags = driver.find_elements_by_xpath(\"//p[@class='company body-medium']\")\n",
    "days_ago_tags = driver.find_elements_by_xpath(\"//span[@class='body-small-l'][1]\")\n",
    "rating_tags = driver.find_elements_by_xpath(\"//span[@class='body-small']\")\n",
    "\n",
    "for i in company_name_tags:\n",
    "    name = i.text\n",
    "    company_names.append(name)\n",
    "    \n",
    "for j in days_ago_tags:\n",
    "    days = j.text\n",
    "    days_ago.append(days)\n",
    "    \n",
    "for k in rating_tags:\n",
    "    rating = k.text\n",
    "    company_rating.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec8d6544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(company_names),len(days_ago),len(company_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "800dc832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "jobs = pd.DataFrame({})\n",
    "jobs['company name'] = company_names\n",
    "jobs['no.of days ago'] = days_ago\n",
    "jobs['rating'] = company_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a89ec4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company name</th>\n",
       "      <th>no.of days ago</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TECHNIP GLOBAL BUSINESS SERVICES PRIVATE LIMITED</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bristlecone India Limited</td>\n",
       "      <td>14d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zyoin</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Newgen Software Technologies Ltd.</td>\n",
       "      <td>21d ago</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JK Technosoft Ltd</td>\n",
       "      <td>29d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pitney Bowes India Pvt Ltd</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       company name no.of days ago rating\n",
       "0                  EXL Services.com ( I ) Pvt. Ltd.         7d ago    3.9\n",
       "1                     GENPACT India Private Limited        19d ago    4.0\n",
       "2  TECHNIP GLOBAL BUSINESS SERVICES PRIVATE LIMITED         5d ago    3.9\n",
       "3                     GENPACT India Private Limited       1mon ago    4.0\n",
       "4                         Bristlecone India Limited        14d ago    3.8\n",
       "5                                             Zyoin        19d ago    4.1\n",
       "6                Ashkom Media India Private Limited         5d ago    3.7\n",
       "7                 Newgen Software Technologies Ltd.        21d ago    3.5\n",
       "8                                 JK Technosoft Ltd        29d ago    3.7\n",
       "9                        Pitney Bowes India Pvt Ltd       1mon ago    4.2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902bab28",
   "metadata": {},
   "source": [
    "# Answer-10 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "628103f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary\n",
    "#First get the webpage https://www.ambitionbox.com/\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32cfa0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on the salaries option.\n",
    "salary_option_link = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "salary_option_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1aef6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "search_job_profile = driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "search_job_profile.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fe7dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_profile = driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p\")\n",
    "job_profile.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c39fcccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store job company names, total salary record, avg salary, min salary, max salary, exp required.\n",
    "company_names = []\n",
    "total_salary_record = []\n",
    "avg_salary = []\n",
    "min_salary = []\n",
    "max_salary = []\n",
    "exp_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1731baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = driver.find_elements_by_xpath(\"//div[@class='name']/a\")\n",
    "total_salary_record_tags = driver.find_elements_by_xpath(\"//div[@class='name']/span\")\n",
    "avg_salary_tags = driver.find_elements_by_xpath(\"//div[@class='average-indicator-wrapper']/p\")\n",
    "min_salary_tags = driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[1]\")\n",
    "max_salary_tags = driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[2]\")\n",
    "exp_required_tags = driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\")\n",
    "\n",
    "for i in name_tags:\n",
    "    name = i.text\n",
    "    company_names.append(name)\n",
    "    \n",
    "for j in total_salary_record_tags:\n",
    "    salary_record = j.text.replace('based on','')\n",
    "    total_salary_record.append(salary_record)\n",
    "    \n",
    "for k in avg_salary_tags:\n",
    "    avg_sal = k.text\n",
    "    avg_salary.append(avg_sal)\n",
    "\n",
    "for l in min_salary_tags:\n",
    "    min_sal = l.text\n",
    "    min_salary.append(min_sal)\n",
    "    \n",
    "for m in max_salary_tags:\n",
    "    max_sal = m.text\n",
    "    max_salary.append(max_sal)\n",
    "    \n",
    "for n in exp_required_tags:\n",
    "    experience = n.text.replace('Data Scientist','').replace('.','').replace('\\n','')\n",
    "    exp_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "226a5155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(company_names),len(total_salary_record),len(avg_salary),len(min_salary),len(max_salary),len(exp_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a17b3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "jobs = pd.DataFrame({})\n",
    "jobs['company name'] = company_names\n",
    "jobs['total salary record'] = total_salary_record\n",
    "jobs['avg salary'] = avg_salary\n",
    "jobs['min salary'] = min_salary\n",
    "jobs['max salary'] = max_salary\n",
    "jobs['experience'] = exp_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80c928b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company name</th>\n",
       "      <th>total salary record</th>\n",
       "      <th>avg salary</th>\n",
       "      <th>min salary</th>\n",
       "      <th>max salary</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 29.7L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>3 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>32 salaries</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 18.9L</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>27 salaries</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>81 salaries</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>46 salaries</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>53 salaries</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               company name total salary record avg salary min salary  \\\n",
       "0                   Walmart         11 salaries    ₹ 29.7L    ₹ 25.0L   \n",
       "1                  Ab Inbev         32 salaries    ₹ 20.5L    ₹ 15.0L   \n",
       "2              Reliance Jio         10 salaries    ₹ 18.9L     ₹ 5.6L   \n",
       "3                        ZS         15 salaries    ₹ 15.9L     ₹ 9.8L   \n",
       "4                     Optum         27 salaries    ₹ 15.2L    ₹ 11.0L   \n",
       "5         Fractal Analytics         81 salaries    ₹ 15.2L     ₹ 9.5L   \n",
       "6           Tiger Analytics         46 salaries    ₹ 14.8L     ₹ 9.0L   \n",
       "7              UnitedHealth         53 salaries    ₹ 14.0L     ₹ 8.3L   \n",
       "8                   Verizon         14 salaries    ₹ 12.7L    ₹ 10.0L   \n",
       "9  Ganit Business Solutions         13 salaries    ₹ 12.4L     ₹ 8.5L   \n",
       "\n",
       "  max salary     experience  \n",
       "0    ₹ 35.0L      3 yrs exp  \n",
       "1    ₹ 25.5L    3-4 yrs exp  \n",
       "2    ₹ 26.2L      4 yrs exp  \n",
       "3    ₹ 20.0L      2 yrs exp  \n",
       "4    ₹ 22.0L    3-4 yrs exp  \n",
       "5    ₹ 22.0L    2-4 yrs exp  \n",
       "6    ₹ 20.0L    2-4 yrs exp  \n",
       "7    ₹ 20.5L    2-4 yrs exp  \n",
       "8    ₹ 21.0L      4 yrs exp  \n",
       "9    ₹ 15.0L      4 yrs exp  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78f2f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close automated chrome window\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

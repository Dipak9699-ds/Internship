{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a8b7f6",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1806af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9207738",
   "metadata": {},
   "source": [
    "# Answer-1 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e153ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to display all the header tags from wikipedia.org\n",
    "\n",
    "wikipedia_page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "wikipedia_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13fb1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(wikipedia_page.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d620a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "print('list of all header tags :',*header,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2dd726",
   "metadata": {},
   "source": [
    "# Answer-2 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649ad01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n",
    "imdb_page = requests.get('https://www.imdb.com/search/title/?count=100&groups=top_1000&sort=user_rating')\n",
    "imdb_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b444339",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_soup = BeautifulSoup(imdb_page.content,'html.parser')\n",
    "imdb_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8cab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = imdb_soup.find_all('div',class_=\"lister-item mode-advanced\")\n",
    "movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59865d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping top100 movie names, ratings and year of release.\n",
    "movie_name = []\n",
    "movie_rating = []\n",
    "movie_year = []\n",
    "\n",
    "for i in movie_data:\n",
    "    name = i.h3.a.text\n",
    "    movie_name.append(name)\n",
    "\n",
    "    rating = i.find('div',class_='inline-block ratings-imdb-rating')\n",
    "    movie_rating.append(rating.text.replace('\\n',''))\n",
    "\n",
    "    year_of_release = i.h3.find('span',class_='lister-item-year text-muted unbold').text\n",
    "    movie_year.append(year_of_release.replace('(','').replace(')',''))\n",
    "    \n",
    "print('movie_name :-',movie_name,sep='\\n\\n')\n",
    "print('\\nmovie_ratings :-',movie_rating,sep='\\n\\n')\n",
    "print('\\nyear_of_release :-',movie_year,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe.\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'movie_name':movie_name,'rating':movie_rating,'year':movie_year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837c23f",
   "metadata": {},
   "source": [
    "# Answer-3 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n",
    "indian_imdb_page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "indian_imdb_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_imdb_soup = BeautifulSoup(indian_imdb_page.content,'html.parser')\n",
    "indian_imdb_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11cc8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping top100 indian movie names, ratings, year_of_release.\n",
    "\n",
    "#scraping top100 indian movie names.\n",
    "indian_movie_name = []\n",
    "indian_movie_rating = []\n",
    "indian_movie_yor = []\n",
    "\n",
    "for i in indian_imdb_soup.find_all('td',class_=\"titleColumn\"):\n",
    "    if(len(indian_movie_name) < 100):\n",
    "        indian_movie_name.append(i.a.text)\n",
    "print('indian_movie_name :-',indian_movie_name,sep='\\n\\n')\n",
    "\n",
    "#scraping top100 indian movie ratings.\n",
    "for i in indian_imdb_soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    if(len(indian_movie_rating) < 100):\n",
    "        indian_movie_rating.append(i.text.replace('\\n',''))\n",
    "print('\\nindian_movie_ratings :-',indian_movie_rating,sep='\\n\\n')\n",
    "\n",
    "#scraping indian movie year of release.\n",
    "for i in indian_imdb_soup.find_all('td',class_=\"titleColumn\"):\n",
    "    if(len(indian_movie_yor) < 100):\n",
    "        indian_movie_yor.append(i.span.text.replace('(','').replace(')',''))\n",
    "print('\\nyear_of_release :-',indian_movie_yor,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4de692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe.\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'movie_name':indian_movie_name,'rating':indian_movie_rating,'year':indian_movie_yor})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be401b6b",
   "metadata": {},
   "source": [
    "# Answer-4 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ea555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to scrape product name, price and discounts from https://meesho.com/bagsladies/pl/p7vbp.\n",
    "product_page = requests.get('https://meesho.com/bags-ladies/pl/p7vbp')\n",
    "product_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80300f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_soup = BeautifulSoup(product_page.content,'html.parser')\n",
    "product_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping product name,price,discount.\n",
    "product_name = [] #empty list\n",
    "product_price = [] #empty list\n",
    "product_discount = [] #empty list\n",
    "\n",
    "#scraping product name.\n",
    "for i in product_soup.find_all('div',class_=\"Card__BaseCard-sc-b3n78k-0 dUNFgg NewProductCard__DetailCard_Desktop-sc-j0e7tu-2 fqvaeS NewProductCard__DetailCard_Desktop-sc-j0e7tu-2 fqvaeS\"):\n",
    "    product_name.append(i.p.text)\n",
    "    \n",
    "print('product_name :-',product_name,sep='\\n\\n')\n",
    "\n",
    "#scraping product price.\n",
    "for i in product_soup.find_all('div',class_=\"Card__BaseCard-sc-b3n78k-0 dUNFgg NewProductCard__DetailCard_Desktop-sc-j0e7tu-2 fqvaeS NewProductCard__DetailCard_Desktop-sc-j0e7tu-2 fqvaeS\"):\n",
    "    product_price.append(i.h5.text)\n",
    "    \n",
    "print('\\nproduct_price :-',product_price,sep='\\n\\n')\n",
    "\n",
    "#scraping product discount.\n",
    "for i in product_soup.find_all('div',class_=\"Card__BaseCard-sc-b3n78k-0 iJCKg NewProductCard__DiscountRow-sc-j0e7tu-15 kUcVjG NewProductCard__DiscountRow-sc-j0e7tu-15 kUcVjG\"):\n",
    "    product_discount.append(i.p.text.replace(' ','').replace('discount','').replace('on','').replace('1st','').replace('order',''))\n",
    "    \n",
    "print('\\nproduct_discount :-',product_discount,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14992b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe.\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'product_name':product_name,'price':product_price,'discount':product_discount})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a395887",
   "metadata": {},
   "source": [
    "# Answer-5 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bedd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to scrape cricket rankings from icc-cricket.com.\n",
    "\n",
    "#(a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "icc_odi_team_page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "icc_odi_team_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9bb3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(icc_odi_team_page.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b34dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping top odi team, team matches, points, rating\n",
    "odi_team = []\n",
    "odi_team_matches = []\n",
    "odi_team_points = []\n",
    "odi_team_rating = []\n",
    "\n",
    "#scraping code for top10 odi team.\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    odi_team.append(i.text)\n",
    "odi_team = odi_team[0:10]\n",
    "print('odi_top10_team :-',odi_team,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 odi team matches.\n",
    "odi_team_matches_banner = soup.find('td',class_=\"rankings-block__banner--matches\")\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    odi_team_matches.append(i.text)\n",
    "    \n",
    "odi_team_matches = odi_team_matches[0::2]\n",
    "odi_team_matches.insert(0,odi_team_matches_banner.text)\n",
    "odi_team_matches = odi_team_matches[0:10]\n",
    "print('\\nodi_top10_team_matches :-',odi_team_matches,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 odi points.\n",
    "odi_team_points_banner = soup.find('td',class_=\"rankings-block__banner--points\")\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    odi_team_points.append(i.text)\n",
    "    \n",
    "odi_team_points = odi_team_points[1::2]\n",
    "odi_team_points.insert(0,odi_team_points_banner.text)\n",
    "odi_team_points = odi_team_points[0:10]\n",
    "print('\\nodi_top10_team_points :-',odi_team_points,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 odi rating.\n",
    "odi_team_rating_banner = soup.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "odi_team_rating_banner = odi_team_rating_banner.text.replace(' ','').replace('\\n','')\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    odi_team_rating.append(i.text)\n",
    "odi_team_rating.insert(0,odi_team_rating_banner)\n",
    "odi_team_rating = odi_team_rating[0:10]\n",
    "print('\\nodi_top10_team_rating :-',odi_team_rating[0:10],sep='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad26c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe.\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'odi_top10_team':odi_team,'matches':odi_team_matches,'points':odi_team_points,'rating':odi_team_rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "icc_odi_player_page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "icc_odi_player_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d230c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(icc_odi_player_page.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping top 10 odi batsman, team, rating.\n",
    "odi_top10_batsman = []\n",
    "odi_top10_batsman_team = []\n",
    "odi_top10_batsman_rating = []\n",
    "\n",
    "#scraping code for top10 odi batsman.\n",
    "odi_top10_batsman_banner = soup.find('div',class_=\"rankings-block__banner--name\")\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    odi_top10_batsman.append(i.a.text)\n",
    "    \n",
    "odi_top10_batsman.insert(0,odi_top10_batsman_banner.text)\n",
    "odi_top10_batsman = odi_top10_batsman[0:10]\n",
    "print('\\nodi_top10_batsman :-',odi_top10_batsman,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 odi batsman team.\n",
    "odi_top10_batsman_team_banner = soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "odi_top10_batsman_team_banner = odi_top10_batsman_team_banner.text.replace('\\n','').rstrip(\"891\")\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    odi_top10_batsman_team.append(i.text)\n",
    "    \n",
    "odi_top10_batsman_team.insert(0,odi_top10_batsman_team_banner)\n",
    "odi_top10_batsman_team = odi_top10_batsman_team[0:10]\n",
    "print('\\nodi_top10_batsman_team :-',odi_top10_batsman_team,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 odi batsman .\n",
    "odi_top10_batsman_rating_banner = soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    odi_top10_batsman_rating.append(i.text)\n",
    "    \n",
    "odi_top10_batsman_rating.insert(0,odi_top10_batsman_rating_banner.text)\n",
    "odi_top10_batsman_rating = odi_top10_batsman_rating[0:10]\n",
    "print('\\nodi_top10_batsman_rating :-',odi_top10_batsman_rating,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f22f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe.\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'odi_top10_batsman':odi_top10_batsman,'team':odi_top10_batsman_team,'rating':odi_top10_batsman_rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "#scraping top 10 odi bowler, team, rating.\n",
    "odi_top10_bowler = []\n",
    "odi_top10_bowler_team = []\n",
    "odi_top10_bowler_rating = []\n",
    "\n",
    "#scraping code for top10 odi bowler.\n",
    "odi_top10_bowler_banner = []\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name\"):\n",
    "    odi_top10_bowler_banner.append(i.text)\n",
    "#odi_top10_bowler_banner[1]\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    odi_top10_bowler.append(i.a.text)\n",
    "odi_top10_bowler = odi_top10_bowler[9:18]    \n",
    "\n",
    "odi_top10_bowler.insert(0,odi_top10_bowler_banner[1])\n",
    "print('\\nodi_top10_bowler :-',odi_top10_bowler,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 odi bowler team.\n",
    "odi_top10_bowler_team_banner = []\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    odi_top10_bowler_team_banner.append(i.text.replace('\\n','').rstrip('726'))\n",
    "#odi_top10_bowler_team_banner[1]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    odi_top10_bowler_team.append(i.text)\n",
    "odi_top10_bowler_team = odi_top10_bowler_team[9:18]        \n",
    "odi_top10_bowler_team\n",
    "\n",
    "odi_top10_bowler_team.insert(0,odi_top10_bowler_team_banner[1])\n",
    "print('\\nodi_top10_bowler_team :-',odi_top10_bowler_team,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 odi bowler rating.\n",
    "odi_top10_bowler_rating_banner = []\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    odi_top10_bowler_rating_banner.append(i.text)\n",
    "#odi_top10_bowler_rating_banner[1]\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    odi_top10_bowler_rating.append(i.text)\n",
    "odi_top10_bowler_rating = odi_top10_bowler_rating[9:18]        \n",
    "odi_top10_bowler_rating\n",
    "\n",
    "odi_top10_bowler_rating.insert(0,odi_top10_bowler_rating_banner[1])\n",
    "print('\\nodi_top10_bowler_rating :-',odi_top10_bowler_rating,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'odi_top10_bowler':odi_top10_bowler,'team':odi_top10_bowler_team,'rating':odi_top10_bowler_rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd482b",
   "metadata": {},
   "source": [
    "# Answer-6 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1124f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to scrape cricket rankings from icc-cricket.com.\n",
    "\n",
    "#(a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "icc_odi_women_team_page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "icc_odi_women_team_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1960f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(icc_odi_women_team_page.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba8cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping top women odi team, team matches, points, rating.\n",
    "odi_team = []\n",
    "odi_team_matches = []\n",
    "odi_team_points = []\n",
    "odi_team_rating = []\n",
    "\n",
    "#scraping code for top10 women odi team\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    odi_team.append(i.text)\n",
    "odi_team = odi_team[0:10]\n",
    "print('odi_top10_women_team :-',odi_team,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 women odi team matches\n",
    "odi_team_matches_banner = soup.find('td',class_=\"rankings-block__banner--matches\")\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    odi_team_matches.append(i.text)\n",
    "    \n",
    "odi_team_matches = odi_team_matches[0::2]\n",
    "odi_team_matches.insert(0,odi_team_matches_banner.text)\n",
    "odi_team_matches = odi_team_matches[0:10]\n",
    "print('\\nodi_top10_women_team_matches :-',odi_team_matches,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 women odi points\n",
    "odi_team_points_banner = soup.find('td',class_=\"rankings-block__banner--points\")\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    odi_team_points.append(i.text)\n",
    "    \n",
    "odi_team_points = odi_team_points[1::2]\n",
    "odi_team_points.insert(0,odi_team_points_banner.text)\n",
    "odi_team_points = odi_team_points[0:10]\n",
    "print('\\nodi_top10_women_team_points :-',odi_team_points,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 women odi rating\n",
    "odi_team_rating_banner = soup.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "odi_team_rating_banner = odi_team_rating_banner.text.replace(' ','').replace('\\n','')\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    odi_team_rating.append(i.text)\n",
    "odi_team_rating.insert(0,odi_team_rating_banner)\n",
    "odi_team_rating = odi_team_rating[0:10]\n",
    "print('\\nodi_top10_women_team_rating :-',odi_team_rating[0:10],sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe.\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'odi_top10_women_team':odi_team,'matches':odi_team_matches,'points':odi_team_points,'rating':odi_team_rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f624f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "icc_odi_women_player_page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "icc_odi_women_player_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78da4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(icc_odi_women_player_page.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c5ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping top 10 women odi batsman, team, rating.\n",
    "odi_top10_batsman = []\n",
    "odi_top10_batsman_team = []\n",
    "odi_top10_batsman_rating = []\n",
    "\n",
    "#scraping code for top10 women odi batsman\n",
    "odi_top10_batsman_banner = soup.find('div',class_=\"rankings-block__banner--name\")\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    odi_top10_batsman.append(i.a.text)\n",
    "    \n",
    "odi_top10_batsman.insert(0,odi_top10_batsman_banner.text)\n",
    "odi_top10_batsman = odi_top10_batsman[0:10]\n",
    "print('\\nodi_top10_women_batsman :-',odi_top10_batsman,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 women odi batsman team\n",
    "odi_top10_batsman_team_banner = soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "odi_top10_batsman_team_banner = odi_top10_batsman_team_banner.text.replace('\\n','').rstrip(\"785\")\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    odi_top10_batsman_team.append(i.text)\n",
    "    \n",
    "odi_top10_batsman_team.insert(0,odi_top10_batsman_team_banner)\n",
    "odi_top10_batsman_team = odi_top10_batsman_team[0:10]\n",
    "print('\\nodi_top10_women_batsman_team :-',odi_top10_batsman_team,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 women odi batsman rating\n",
    "odi_top10_batsman_rating_banner = soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    odi_top10_batsman_rating.append(i.text)\n",
    "    \n",
    "odi_top10_batsman_rating.insert(0,odi_top10_batsman_rating_banner.text)\n",
    "odi_top10_batsman_rating = odi_top10_batsman_rating[0:10]\n",
    "print('\\nodi_top10_women_batsman_rating :-',odi_top10_batsman_rating,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a780ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'odi_top10_women_batsman':odi_top10_batsman,'team':odi_top10_batsman_team,'rating':odi_top10_batsman_rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a034654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(c) Top 10 women ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "#scraping top 10 odi bowler, team, rating\n",
    "odi_top10_bowler = []\n",
    "odi_top10_bowler_team = []\n",
    "odi_top10_bowler_rating = []\n",
    "\n",
    "#scraping code for top10 odi bowler\n",
    "odi_top10_bowler_banner = []\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name\"):\n",
    "    odi_top10_bowler_banner.append(i.text)\n",
    "#odi_top10_bowler_banner[1]\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    odi_top10_bowler.append(i.a.text)\n",
    "odi_top10_bowler = odi_top10_bowler[9:18]    \n",
    "\n",
    "odi_top10_bowler.insert(0,odi_top10_bowler_banner[1])\n",
    "print('\\nodi_top10_women_bowler :-',odi_top10_bowler,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 odi bowler team\n",
    "odi_top10_bowler_team_banner = []\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    odi_top10_bowler_team_banner.append(i.text.replace('\\n','').rstrip('771'))\n",
    "#odi_top10_bowler_team_banner[1]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    odi_top10_bowler_team.append(i.text)\n",
    "odi_top10_bowler_team = odi_top10_bowler_team[9:18]        \n",
    "odi_top10_bowler_team\n",
    "\n",
    "odi_top10_bowler_team.insert(0,odi_top10_bowler_team_banner[1])\n",
    "print('\\nodi_top10_women_bowler_team :-',odi_top10_bowler_team,sep='\\n\\n')\n",
    "\n",
    "#scraping code for top10 odi bowler rating\n",
    "odi_top10_bowler_rating_banner = []\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    odi_top10_bowler_rating_banner.append(i.text)\n",
    "#odi_top10_bowler_rating_banner[1]\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    odi_top10_bowler_rating.append(i.text)\n",
    "odi_top10_bowler_rating = odi_top10_bowler_rating[9:18]        \n",
    "odi_top10_bowler_rating\n",
    "\n",
    "odi_top10_bowler_rating.insert(0,odi_top10_bowler_rating_banner[1])\n",
    "print('\\nodi_top10_women_bowler_rating :-',odi_top10_bowler_rating,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40367418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'odi_top10_women__bowler':odi_top10_bowler,'team':odi_top10_bowler_team,'rating':odi_top10_bowler_rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00755fb7",
   "metadata": {},
   "source": [
    "# Answer-7 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e9486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to scrape details of all the posts from coreyms.com. \n",
    "#Scrape the heading, date, content and the code for the video from the link for the youtube video from the post.\n",
    "\n",
    "blogpost_page = requests.get('https://coreyms.com')\n",
    "blogpost_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blogpost_page_soup = BeautifulSoup(blogpost_page.content,'html.parser')\n",
    "blogpost_page_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f3214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping headings, date, content, youtube video link of page.\n",
    "heading = []\n",
    "date = []\n",
    "content = []\n",
    "video_link = []\n",
    "\n",
    "#scraping headings of page\n",
    "for i in blogpost_page_soup.find_all('h2',class_=\"entry-title\"):\n",
    "    heading.append(i.a.text)\n",
    "print('\\nheadings :-',heading,sep='\\n\\n')\n",
    "\n",
    "#scraping date of page.\n",
    "for i in blogpost_page_soup.find_all('time',class_=\"entry-time\"):\n",
    "    date.append(i.text)\n",
    "print('\\ndates :-',date,sep='\\n\\n')\n",
    "\n",
    "#scraping content of page.\n",
    "for i in blogpost_page_soup.find_all('div',class_=\"entry-content\"):\n",
    "    content.append(i.text.replace('\\n',''))\n",
    "print('\\ncontent :-',*content,sep='\\n\\n')\n",
    "\n",
    "#scraping youtube video link of page.\n",
    "iframes = blogpost_page_soup.find_all(\"iframe\")\n",
    "for i in iframes:\n",
    "    src = i['src']\n",
    "    video_link.append(src)\n",
    "    #print('\\nvideo_link :-',src,sep='\\n\\n')\n",
    "print('\\nvideo_link :-',*video_link,sep='\\n\\n')  #show link into list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f35e579",
   "metadata": {},
   "source": [
    "# Answer-8 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e50ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape house details from mentioned URL. It should include house title, location,area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, Rajaji Nagar.\n",
    "\n",
    "house_page = requests.get('https://www.nobroker.in/property/sale/hyderabad/Indira%20Nagar?searchParam=W3sibGF0IjoxNy40NDc0NDc1LCJsb24iOjc4LjM1NjkyNzUsInBsYWNlSWQiOiJDaElKZzVwcF9KU1R5enNSaHBYNzU2M2VkX2ciLCJwbGFjZU5hbWUiOiJJbmRpcmEgTmFnYXIiLCJzaG93TWFwIjpmYWxzZX1d&radius=2.0&city=hyderabad&locality=Indira%20Nagar')\n",
    "house_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8426230",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(house_page.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping  house title, location, area, EMI and price in indiranagar locality.\n",
    "\n",
    "title = [] \n",
    "location_area = []\n",
    "emi = []\n",
    "\n",
    "for i in soup.find_all('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\"):\n",
    "    title.append(i.text)\n",
    "print('title of indiranagar locality :-',title,sep='\\n\\n')\n",
    "\n",
    "for i in soup.find_all('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\"):\n",
    "    location_area.append(i.text)\n",
    "print('\\nlocation_area of indiranagar locality :-',location_area,sep='\\n\\n')\n",
    "\n",
    "for i in soup.find_all('div',class_=\"font-semi-bold heading-6\"):\n",
    "    emi.append(i.text)\n",
    "print('emi_cost of indiranagar locality :-',emi[1:-1:3],sep='\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_page = requests.get('https://www.nobroker.in/property/sale/hyderabad/Jaya%20Nagar?searchParam=W3sibGF0IjoxNy40OTk3NzE1LCJsb24iOjc4LjQwNjI2MjMsInBsYWNlSWQiOiJDaElKUDRreWRlcVJ5enNSOFgwU2hxd2hBM1UiLCJwbGFjZU5hbWUiOiJKYXlhIE5hZ2FyIn1d&radius=2.0&city=hyderabad&locality=Jaya%20Nagar')\n",
    "house_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(house_page.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b58b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping  house title, location, area, EMI and price in jayanagar locality.\n",
    "\n",
    "title = [] #empty list\n",
    "location_area = []\n",
    "emi = []\n",
    "\n",
    "for i in soup.find_all('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\"):\n",
    "    title.append(i.text)\n",
    "print('title of jayanagar locality :-',title,sep='\\n\\n')\n",
    "\n",
    "for i in soup.find_all('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\"):\n",
    "    location_area.append(i.text)\n",
    "print('\\nlocation_area of jayanagar locality :-',location_area,sep='\\n\\n')\n",
    "\n",
    "for i in soup.find_all('div',class_=\"font-semi-bold heading-6\"):\n",
    "    emi.append(i.text)\n",
    "print('emi_cost of jayanagar locality :-',emi[1:-1:3],sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617bce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_page = requests.get('https://www.nobroker.in/property/sale/chennai/Rajaji%20Nagar?searchParam=W3sibGF0IjoxMy4xMTIyNjc3LCJsb24iOjgwLjIwODcyNjUsInBsYWNlSWQiOiJDaElKWTZaNmhFSmtVam9SQ2MyZk9vcEg2dTAiLCJwbGFjZU5hbWUiOiJSYWphamkgTmFnYXIifV0=&radius=2.0&city=chennai&locality=Rajaji%20Nagar')\n",
    "house_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(house_page.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping  house title, location, area, EMI and price in jayanagar locality.\n",
    "\n",
    "title = []\n",
    "location_area = []\n",
    "emi = []\n",
    "\n",
    "for i in soup.find_all('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\"):\n",
    "    title.append(i.text)\n",
    "print('title of rajaji nagar locality :-',title,sep='\\n\\n')\n",
    "\n",
    "for i in soup.find_all('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\"):\n",
    "    location_area.append(i.text)\n",
    "print('\\nlocation_area of rajaji nagar locality :-',location_area,sep='\\n\\n')\n",
    "\n",
    "for i in soup.find_all('div',class_=\"font-semi-bold heading-6\"):\n",
    "    emi.append(i.text)\n",
    "print('emi_cost of rajaji nagar locality :-',emi[1:-1:3],sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68dc578",
   "metadata": {},
   "source": [
    "# Answer-9 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape mentioned details from dineout.co.in\n",
    "\n",
    "resraurant_page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "resraurant_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ca1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(resraurant_page.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fe18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping resraurant name, cuisine, location, rating, image_url.\n",
    "restaurant_name = [] #empty list\n",
    "restaurant_cuisine = [] #empty list\n",
    "restaurant_location = [] #empty list\n",
    "restaurant_rating = [] #empty list\n",
    "restaurant_images = [] #empty list\n",
    "\n",
    "#scraping resraurant name.\n",
    "for i in soup.find_all('div',class_='restnt-info cursor'):\n",
    "    restaurant_name.append(i.text)\n",
    "    \n",
    "print('restaurant_name:-',restaurant_name,sep='\\n\\n')\n",
    "\n",
    "#scraping resraurant cuisine.\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    restaurant_cuisine.append(i.text[22:].replace('|','').replace(' ',''))\n",
    "    \n",
    "print('\\nrestaurant_cuisine:-',restaurant_cuisine,sep='\\n\\n')\n",
    "\n",
    "#scraping resraurant location.\n",
    "for i in soup.find_all('div',class_='restnt-loc ellipsis'):\n",
    "    restaurant_location.append(i.text)\n",
    "    \n",
    "print('\\nrestaurant_location:-',restaurant_location,sep='\\n\\n')\n",
    "\n",
    "#scraping resraurant rating.\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    restaurant_rating.append(i.text)\n",
    "    \n",
    "print('\\nrestaurant_rating:-',restaurant_rating,sep='\\n\\n')\n",
    "\n",
    "#scraping resraurant image url.\n",
    "for i in soup.find_all('img',class_='no-img'):\n",
    "    restaurant_images.append(i['data-src'])\n",
    "    \n",
    "print('\\nrestaurant_images:-',*restaurant_images,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4180ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dataframe.\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Name':restaurant_name,'Cuisine':restaurant_cuisine,'Location':restaurant_location,'Rating':restaurant_rating,'Image_Url':restaurant_images})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caac98e",
   "metadata": {},
   "source": [
    "# Answer-10 :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape first 10 product details which include product name , price , Image URL from https://www.bewakoof.com/women-t-shirts\n",
    "\n",
    "product_page = requests.get('https://www.bewakoof.com/women-plain-t-shirts')\n",
    "product_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126973d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_soup = BeautifulSoup(product_page.content,'html.parser')\n",
    "product_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#roduct_data = product_soup.find_all('div',class_=\"productCardDetail\")\n",
    "#roduct_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77daeab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping product name,price,image_url\n",
    "name = [] \n",
    "price = []\n",
    "image_url = []\n",
    "\n",
    "#scraping product name\n",
    "for i in product_soup.find_all('div',class_=\"productCardDetail\"):\n",
    "    name.append(i.h3.text)\n",
    "    name = name[0:10:1]\n",
    "    \n",
    "#scraping product price\n",
    "for i in product_soup.find_all('span',class_=\"discountedPriceText\"):\n",
    "    price.append(i.text)\n",
    "    price = price[0:10:1]\n",
    "\n",
    "#scraping product image_url \n",
    "img = product_soup.find_all(\"img\")\n",
    "for i in img:\n",
    "    src = i['src']\n",
    "    image_url.append(src)\n",
    "image_url = image_url[4:14:1]\n",
    "\n",
    "print('product_name:-',name,sep='\\n\\n')    \n",
    "print('\\nproduct_price:-',price,sep='\\n\\n')\n",
    "print('\\nproduct_images_url:-',*image_url,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d976c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dataframe.\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'name':name,'price':price,'image_url':image_url})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
